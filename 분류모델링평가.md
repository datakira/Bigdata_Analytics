## 분류(DT, RF, LR)
* Decision Tree : 의사결정 나무라는 의미. 트리 구조를 사용, 각 분기점(node)에는 분석 대상의 속성들이 위치
 - 각 분기점마다 목표 값을 잘 분류할 수 있는 속성을 찾아서 배치
 - 해당 속성이 갖는 값을 이용하여 새로운 가지(branch)를 만듬
 - 데이터 분류 시 최대한 많은 데이터 세트가 해당 분류에 속할 수 있도록 결정 노드의 규칙이 정해져야 함
 - 결정 노드는 정보 균일도가 높은 데이터 세트를 먼저 선택할 수 있도록 규칙 조건을 만듬
 - 정보의 균일도라는 룰을 기반으로 알고리즘이 쉽고 직관적이며 어떻게 규칙 노드와 리프 노드가 
   만들어지는지  알수 있고 시각화로 표현할 수 있는 장점
 - 균일도가 다양하게 존재할 수록 트리의 깊이가 커지고 복잡해 지며 과적합으로 정확도가 떨어진다는 단점
 - 모든 데이터 상황을 만족하는 완벽한규칙은 없다고 인정하고 더 나은 성능을 보장하기 위하여 
   성능 튜닝을 통하여 트리의 크기를 사전에 제한하는 것이 요구됨
   
* 정보 이득 지수 
 - 1- 엔트로피(혼잡도) 지수
 - 정보 이득이 높은 속성을 기준으로 분할

* 지니 계수
 - 다양성이 낮을 수록 균일도가 높다는 의미로 1로 갈수록 균일도가 높으며 
 - 지니 계수가 높은 속성을 기준으로 분할 





```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

# 붓꽃 데이터를 로딩하고 학습과 테스트 데이터 세트로 분리
iris_data = load_iris()
iris_data.keys()
X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,
                                                   test_size = 0.2, random_state=11)
print(iris_data.feature_names)
print(iris_data.target_names)

# DecisionTree Classifier 생성 
# dt_clf = DecisionTreeClassifier(random_state=156)
dt_clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=156)  
# dt_clf = DecisionTreeClassifier(criterion='gini', min_samples_split= 4,random_state=156)  
# dt_clf = DecisionTreeClassifier(criterion='gini', min_samples_leaf= 4,random_state=156)

# DecisionTreeClassifier 학습
dt_clf.fit(X_train, y_train)
y_hat = dt_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_hat)
print("예측 정확도 : {:.4f}".format(accuracy))

```

    ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
    ['setosa' 'versicolor' 'virginica']
    예측 정확도 : 0.9333
    

* DT 파라미터
 - max_depth : 트리의 최대 깊이
 - max_features : 최적의 분할을 위해 고려할 최대 피처 개수
 - max_leaf_nodes : 말단 노드의 최대 개수
 - min_samples_split : 노드를 분할하기 위한 최소한의 샘플 데이터. 디폴트 2. 작게 설정할 수록 분할되는 노드 증가, 과적합 가능성 증가 
 - min_samples_leaf : 말단 노드가 되기 위한 최소한의 샘플 데이터 수

### 결정트리모델의 시각화
* 분꽃 종류 분류 : 
 - SETOSA, VERSICOLOR, VIRGINICA

* 분류 속성 :
 - Petal length(꽃잎 길이), 
 - Petal width(꽃잎 넓이)

* 규칙 조건 : petal length <= 2.45
 - gini : value=[] 데이터 분포에서의 지니 계수
 - samples : 현 규칙에 해당하는 데이터 건수
 - value = [] 클래스 값 기반의 데이터 건수
 - class=setosa는 가장 많은 하위 노드

* 각 노드의 색깔은 붓꽃 데이터의 레이블 값을 의미. 색깔이 짙어 질수록 지니 계수가 낮고 해당 레이블에 속하는 샘플 데이터가 많음



```python
# DT 시각화
from sklearn import tree
import matplotlib.pyplot as plt
%matplotlib inline

plt.figure(figsize=(20,15))
tree.plot_tree(dt_clf, filled=True,
              feature_names=iris_data.feature_names,
              class_names=iris_data.target_names,
              rounded=True, fontsize=14)
plt.show()
plt.close()
```


    
![png](%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%EB%A7%81%ED%8F%89%EA%B0%80_guide_files/%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%EB%A7%81%ED%8F%89%EA%B0%80_guide_4_0.png)
    



```python
import pandas as pd
t_df=pd.read_pickle('./dataset/t_df.pkl')
t_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>7</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>7</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>7</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>




```python
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

# 독립변수, 종속변수 분리
X = t_df.drop('Survived',axis=1)
y = t_df['Survived']

# 독립변수 정규화(평균 0, 분산 1인 표준정규분포)
X = preprocessing.StandardScaler().fit(X).transform(X)

# 학습용 테이터와 평가용 데이터를 8:2로 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \
                                                    random_state=10) 
print(X_train.shape)
print(X_test.shape)
print()
print(X.mean())
print(X.std())
# print(type(y_test))
```

    (712, 8)
    (179, 8)
    
    7.476249324075128e-18
    1.0
    


```python
# Decision Tree
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
dt_pred = dt_model.predict(X_test)

print(dt_pred[0:10])
print(y_test.values[0:10])

accuracy = accuracy_score(y_test, dt_pred)
print('dt 예측 정확도 :', accuracy)
```

    [0 0 0 1 1 0 0 0 0 0]
    [0 0 0 1 1 0 0 0 1 0]
    dt 예측 정확도 : 0.7877094972067039
    


```python
# Random Forest
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

rf_accuracy = accuracy_score(y_test, rf_pred)
print('rf 예측 정확도 :', rf_accuracy)
```

    rf 예측 정확도 : 0.8212290502793296
    


```python
# Logistic Regression
from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression(random_state=0)
lr_model.fit(X_train,y_train)
lr_pred = lr_model.predict(X_test)

lr_accuracy = accuracy_score(y_test, lr_pred)
print('lr 예측 정확도 :', accuracy)
```

    lr 예측 정확도 : 0.7877094972067039
    


```python
# KNN
from sklearn.neighbors import KNeighborsClassifier

k_model = KNeighborsClassifier(n_neighbors=5)
k_model.fit(X_train,y_train)
k_pred = k_model.predict(X_test)

k_accuracy = accuracy_score(y_test, k_pred)
print('k 예측 정확도:', accuracy)

```

    k 예측 정확도: 0.7877094972067039
    


```python
# SVM
from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, f1_score
from sklearn.metrics import classification_report
from sklearn import svm
# 벡터 공간으로 매핑하는 함수를 커널이라고 함. 
# kernel='rbf'옵션으로 RBF(Radial Basis Function) 함수를 적용
svm_model = svm.SVC(kernel='rbf', random_state=0)
svm_model.fit(X_train, y_train)

s_pred = svm_model.predict(X_test)

s_accuracy = accuracy_score(y_test, s_pred)
print('s 정확도:', s_accuracy)

```

    s 정확도: 0.8435754189944135
    

### 평가
* ML 성능평가지표는 일반적으로 모델이 분류냐 회귀냐에 따라 여라 종류로 구분
* 회귀의 경우 실제값과 예측값의 오차 평균값에 기반
* 분류의 경우도 실제 결과 데이터와 예측 결과 데이터가 얼마나 정확하고 오류가 적게 발생하는가에 기반하지만
  이러한 정확도만 가지고 판단했다가는 잘못된 평가 결과에 빠질 수 있으며 정확도외에 오차행렬, 정밀도, 재현율, F1 스코어 ROC AUC
  와 같은 평가지표를 같이 고려해서 수행하는 것이 필요함

### 분류 평가
- 정확도만으로 불균형한 레이블 데이터 세트에서 평가지표로 사용하기에는 부적합
- 정확도가 가지는 분류 평가 지표로의 한계점을 극복하기 위해 여러 가지 분류 지표와 함께 적용해야 함

### Confusion Matrix(혼동행렬, 오차행렬)
* 이진 분류에서 성능 지표로 잘 활용되는 오차행렬(혼동행렬)은 학습된 분류 모델이 예측을 수행하면 얼마나 혼동될 수 있는지도
  함께 보여주는 지표임.
* 이진 분류의 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 보여줌.

### 평가 지표
* TP, FP, FN, TP는 예측 클래스와 실제 클래스의 Positive 결정 값과 Negative 결정 값의 결합에 따라 결정
* 앞문자 True/False는 예측값과 실제값이 같은가/틀린가를 의미하고 뒤 문자 Negative/Positive는 예측 결과 값이 부정/긍정을 의미
* TN는 예측값을 Negative 값 0으로 예측했고 실제값 역시 Negative 값 0
* FP는 예측값을 Positive 값 1로 예측했고 실제값은 Negative 값 0
* FN은 예측값을 Negative 값 0으로 예측했고 실제값은 Positive 값 1
* TP는 예측값을 Positive 값 1로 예측했고 실제값 역시 Positive 값 1
- 정확도 = (TP + TN) / ( TP + TN + FP + FN)
- 정밀도 = TP / ( TP + FP) : P로 예측한 것중에서 실제도 P 
- 재현율 = TP / ( TP + FN) : 실제 P인 것중에서 예측도 P
- F1 = 2 * ( 정밀도 * 재현율) / (정밀도 + 재현율) : 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼때 높아짐.
* 정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표
* 재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우(ex. 보험사기, 암진단)
* 정밀도가 더 중요한 지표인 사례는 스팸 메일 여부를 판단하는 경우로 스팸 메일이 아닌데 스팸 메일로 분류해서 업무 차질 발생

### 정밀도 및 재현율 활용시 유의 사항
* 정밀도와 재현율 성능 수치는 어느 한쪽만 참조하면 극단적인 수치 조작이 가능
* 정밀도 100%가 되는 방법:
  확실한 기준이 되는 경우만 Positive로 예측하고 나머지는 모두 Negative로 예측
  전체 환자 1000명중 확실한 Positive 징후만 가진 환자는 단 1명이라고 하면 이 한 명만 P로 예측하고 나머지는 모두 N으로 예측
  FP는 0, TP는 1이 되며 정밀도(TP/(TP+FP)는 1/(1+0) = 1
* 재현율이 100%가 되는 방법: 
  모든 환자를 Positive로 예측
  1000명의 환자중 실제 양성인 사람이 30명 정도라도 TN이 수치에 포함되지 않고 FN은 0이므로 재현율(TP/(TP+FN)은 30/(30+0) = 1
* 분류가 정밀도, 재현율 중 하나에 상대적인 중요도를 부여할 수 있지만 하나만 강조해서는 안됨
* 암 예측 모델에서 재현율을 높인다고 주로 양성만 판정한다면 환자의 부담과 불평이 커지게 됨

* DT 파라미터
 - max_depth : 트리의 최대 깊이
 - max_features : 최적의 분할을 위해 고려할 최대 피처 개수
 - max_leaf_nodes : 말단 노드의 최대 개수
 - min_samples_split : 노드를 분할하기 위한 최소한의 샘플 데이터. 디폴트 2. 작게 설정할 수록 분할되는 노드 증가, 과적합 가능성 증가 
 - min_samples_leaf : 말단 노드가 되기 위한 최소한의 샘플 데이터 수


```python
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
t_df = pd.read_pickle('./dataset/t_df.pkl')

X = t_df.drop('Survived',axis=1)
y = t_df['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, \
                                                    test_size=0.2, \
                                                    random_state=11)
dt_clf = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
dt_pred = dt_model.predict(X_test)
```


```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
def get_clf_eval(y_test , pred):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    # F1 스코어 추가
    f1 = f1_score(y_test,pred)
    print('오차 행렬')
    print(confusion)
    # f1 score print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))

```


```python
get_clf_eval(y_test, dt_pred)
```

    오차 행렬
    [[99 19]
     [17 44]]
    정확도: 0.7989, 정밀도: 0.6984, 재현율: 0.7213, F1:0.7097
    


```python
# Q. lr, rf, knn, svm 기반으로 타이타닉 생존자 예측하고 confusion matrix, accuracy, precision, recall 평가 수행
```


```python
# Logistic Regression
from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression(random_state=0)
lr_model.fit(X_train,y_train)
lr_pred = lr_model.predict(X_test)
get_clf_eval(y_test, lr_pred)
```

    오차 행렬
    [[104  14]
     [ 13  48]]
    정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869, F1:0.7805
    


```python
# Random Forest
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
get_clf_eval(y_test, rf_pred)
```

    오차 행렬
    [[108  10]
     [ 16  45]]
    정확도: 0.8547, 정밀도: 0.8182, 재현율: 0.7377, F1:0.7759
    


```python
# KNN
from sklearn.neighbors import KNeighborsClassifier

k_model = KNeighborsClassifier(n_neighbors=5)
k_model.fit(X_train,y_train)
k_pred = k_model.predict(X_test)
get_clf_eval(y_test, k_pred)
```

    오차 행렬
    [[100  18]
     [ 28  33]]
    정확도: 0.7430, 정밀도: 0.6471, 재현율: 0.5410, F1:0.5893
    


```python
# SVM
from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix, f1_score
from sklearn.metrics import classification_report
from sklearn import svm
# 벡터 공간으로 매핑하는 함수를 커널이라고 함. 
# kernel='rbf'옵션으로 RBF(Radial Basis Function) 함수를 적용
svm_model = svm.SVC(kernel='rbf', random_state=0)
svm_model.fit(X_train, y_train)

s_pred = svm_model.predict(X_test)
get_clf_eval(y_test, s_pred)
```

    오차 행렬
    [[110   8]
     [ 42  19]]
    정확도: 0.7207, 정밀도: 0.7037, 재현율: 0.3115, F1:0.4318
    

### ROC 곡선과 AUC
* 수신자 판단 곡선이라고 하며 ML의 이진 분류 모델의 예측 성능을 판단하는 중요한 평가 지표.
* TPR은 재현율(민감도)를 나타내며 TNR(특이성)은 실제값 N이 정확히 예측되어야 하는수준으로 TN/(FP+TN)
* FPR은 1- 특이성(TNR), 
* FPR이 변할 때 TPR이 어떻게 변하는지를 나타내는 곡선으로  
* ROC 곡선은 FPR을 0부터 1까지 변경하면서 FPR을 구하고 이 FPR값의 변화에 따른 TPR의 변화 값을 구함.
* FPR을 0에서 1까지 변경하는 것은 Positive 예측값을 결정하는 기준인 분류 결정 임곗값을 변경하면 됨. 
* FPR을 0으로 만들려면 임곗값을 1로 지정하고 반대로 FPR을 1로 만들려면 임곗값을 0으로 지정하면 됨.


```python
from sklearn.linear_model import LogisticRegression

lr_clf = LogisticRegression(random_state=0)
lr_clf.fit(X_train,y_train)
lr_pred = lr_model.predict(X_test)

# Precision/Recall Trade-off
pred_proba = lr_clf.predict_proba(X_test)
pred  = lr_clf.predict(X_test)
print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))
print('pred_proba array에서 앞 3개만 샘플로 추출 \n:', pred_proba[:3])

# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인
pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)
print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n',pred_proba_result[:3])
```

    pred_proba()결과 Shape : (179, 2)
    pred_proba array에서 앞 3개만 샘플로 추출 
    : [[0.4616653  0.5383347 ]
     [0.87862763 0.12137237]
     [0.87727002 0.12272998]]
    두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 
     [[0.4616653  0.5383347  1.        ]
     [0.87862763 0.12137237 0.        ]
     [0.87727002 0.12272998 0.        ]]
    


```python
from sklearn.metrics import precision_recall_curve

# 레이블 값이 1일때의 예측 확률을 추출 
pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] 

# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 
precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1 )
print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)

#반환된 임계값 배열 로우가 143건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. 
thr_index = np.arange(0, thresholds.shape[0], 15)
print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)
print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))

# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 
print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))
print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))
```

    반환된 분류 결정 임곗값 배열의 Shape: (143,)
    샘플 추출을 위한 임계값 배열의 index 10개: [  0  15  30  45  60  75  90 105 120 135]
    샘플용 10개의 임곗값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.57 0.67 0.82 0.95]
    샘플 임계값별 정밀도:  [0.389 0.44  0.466 0.539 0.647 0.729 0.836 0.949 0.958 1.   ]
    샘플 임계값별 재현율:  [1.    0.967 0.902 0.902 0.902 0.836 0.754 0.607 0.377 0.148]
    


```python
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
%matplotlib inline

def precision_recall_curve_plot(y_test , pred_proba_c1):
    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. 
    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)
    
    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시
    plt.figure(figsize=(8,6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')
    
    # threshold 값 X 축의 Scale을 0.1 단위로 변경
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1),2))
    
    # x축, y축 label과 legend, 그리고 grid 설정
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()
    plt.show()
    
precision_recall_curve_plot( y_test, lr_clf.predict_proba(X_test)[:, 1] )
```


    
![png](%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%EB%A7%81%ED%8F%89%EA%B0%80_guide_files/%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%EB%A7%81%ED%8F%89%EA%B0%80_guide_26_0.png)
    


### 결과 해석
* 임계값이 낮을수록 많은 수의 양성 예측으로 인해 재현율 값이 극도로 높아지고 정밀도 값이 낮아짐.(FN이 작아지고 FP가 커짐)
* 로지스틱 회귀 기반의 타이타닉 생존자 예측 모델의 경우 임곗값이 약 0.45 지점에서 재현율과 정밀도가 비슷해지는 모습을 보임.
* 단순히 하나의 성능 지료 수치를 높이기 위한 수단으로 사용하는 것은 지양하고 업무 환경에 맞게 두 개의 수치를 상호 보완할 수 있는 수준에서 적용


```python
from sklearn.metrics import roc_curve

# 레이블 값이 1일때의 예측 확률을 추출 
pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1] 

fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)
# 반환된 임곗값 배열 로우가 143건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출. 
thr_index = np.arange(0, thresholds.shape[0], 5)
print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)
print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))

# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값
print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))
print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))
```

    샘플 추출을 위한 임곗값 배열의 index 10개: [ 0  5 10 15 20 25 30 35 40 45 50]
    샘플용 10개의 임곗값:  [1.97 0.75 0.63 0.59 0.49 0.4  0.31 0.15 0.12 0.11 0.1 ]
    샘플 임곗값별 FPR:  [0.    0.017 0.034 0.059 0.127 0.161 0.237 0.483 0.61  0.703 0.814]
    샘플 임곗값별 TPR:  [0.    0.475 0.672 0.754 0.787 0.852 0.885 0.902 0.934 0.967 0.984]
    


```python
import matplotlib.pyplot as plt
def roc_curve_plot(y_test , pred_proba_c1):
    # 임곗값에 따른 FPR, TPR 값을 반환 받음. 
    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)

    # ROC Curve를 plot 곡선으로 그림. 
    plt.plot(fprs , tprs, label='ROC')
    # 가운데 대각선 직선을 그림. 
    plt.plot([0, 1], [0, 1], 'k--', label='Random')
    
    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1),2))
    plt.xlim(0,1); plt.ylim(0,1)
    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')
    plt.legend()
    plt.show()
    
roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )
```


    
![png](%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%EB%A7%81%ED%8F%89%EA%B0%80_guide_files/%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8%EB%A7%81%ED%8F%89%EA%B0%80_guide_29_0.png)
    



```python
from sklearn.metrics import roc_auc_score

pred = lr_clf.predict(X_test)
roc_score = roc_auc_score(y_test, pred)
print('ROC AUC 값: {0:.4f}'.format(roc_score))
```

    ROC AUC 값: 0.8341
    


```python
def get_clf_eval(y_test , pred):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    f1 = f1_score(y_test,pred)
    # ROC-AUC 추가 
    roc_auc = roc_auc_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))
```


```python
get_clf_eval(y_test,lr_pred)
```

    오차 행렬
    [[104  14]
     [ 13  48]]
    정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869,    F1: 0.7805, AUC:0.8341
    


```python
get_clf_eval(y_test,rf_pred)
```

    오차 행렬
    [[108  10]
     [ 16  45]]
    정확도: 0.8547, 정밀도: 0.8182, 재현율: 0.7377,    F1: 0.7759, AUC:0.8265
    


```python
get_clf_eval(y_test,dt_pred)
```

    오차 행렬
    [[99 19]
     [17 44]]
    
    정확도: 0.7989, 정밀도: 0.6984, 재현율: 0.7213,    F1: 0.7097, AUC:0.8341
    

## 참고 사항
- 모델링 결과에 대한 상세 평가 방법
- 모델링 경과에 대한 교차 검증과 성능 개선 동시 수행(GridSearchCV)


```python
# GridSearchCV : 교차검증과 성능 개선을 위한 하이퍼파라미터 튜닝을 동시에 수행
# 교차 검증을 기반으로 하이퍼 파라미터의 최적 값을 찾게 해줌
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score , \
recall_score ,confusion_matrix, f1_score, roc_auc_score

parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5],\
              'min_samples_leaf':[1,5,8]}

grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', \
                         cv=5, refit=True)
grid_dclf.fit(X_train, y_train)
print(grid_dclf)
print('GridSearchCV 최적 하이퍼 파라미터:', grid_dclf.best_params_)
print('GridSeachCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))

best_dclf = grid_dclf.best_estimator_
print(best_dclf)
dpredictions = best_dclf.predict(X_test)
accuracy = accuracy_score(y_test, dpredictions)
print('dt 예측 정확도 :', accuracy)

def get_clf_eval(y_test , dpredictions):
    confusion = confusion_matrix( y_test, dpredictions)
    accuracy = accuracy_score(y_test , dpredictions)
    precision = precision_score(y_test , dpredictions)
    recall = recall_score(y_test , dpredictions)
    f1 = f1_score(y_test,dpredictions)
    roc_auc = roc_auc_score(y_test, pred)
    print('오차 행렬')
    print(confusion)
    print()    
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))
get_clf_eval(y_test , dpredictions)
```

    GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),
                 param_grid={'max_depth': [2, 3, 5, 10],
                             'min_samples_leaf': [1, 5, 8],
                             'min_samples_split': [2, 3, 5]},
                 scoring='accuracy')
    GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}
    GridSeachCV 최고 정확도: 0.7992
    DecisionTreeClassifier(max_depth=3, min_samples_leaf=5)
    dt 예측 정확도 : 0.8715083798882681
    오차 행렬
    [[109   9]
     [ 14  47]]
    
    정확도: 0.8715, 정밀도: 0.8393, 재현율: 0.7705,    F1: 0.8034, AUC:0.8341
    
