```python
import numpy as np
import pandas as pd
from scipy import stats
from matplotlib import pyplot as plt
import seaborn as sns
sns.set()
import statsmodels.formula.api as smf
import statsmodels.api as sm
```


```python
# 데이터 읽기 : 맥주 매상 데이터
beer = pd.read_csv("./dataset/7_1_beer.csv")
print(beer.head())
```

       beer  temperature
    0  45.3         20.5
    1  59.3         25.0
    2  40.4         10.0
    3  38.0         26.9
    4  37.0         15.8
    


```python
# 그래프
sns.jointplot(x='temperature',y='beer', kind='reg',
            data=beer, color='skyblue')
```




    <seaborn.axisgrid.JointGrid at 0x24648ec76d0>




    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_2_1.png)
    



```python
# 모델 구축 : 종속 변수 맥주 매상, 독립 변수 기온을 사용한 정규선형모델
# 모집단분포가 정규분포임을 가정 시 최대우도법의 결과는 최소제곱법의 결과와 일치
# Ordinary Least Squares(범용최소제곱법)
lm_model = smf.ols(formula = "beer ~ temperature",
                  data = beer).fit()
```


```python
lm_model.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>beer</td>       <th>  R-squared:         </th> <td>   0.504</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.486</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.45</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 21 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>1.11e-05</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:33:20</td>     <th>  Log-Likelihood:    </th> <td> -102.45</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   208.9</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   211.7</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>   <td>   34.6102</td> <td>    3.235</td> <td>   10.699</td> <td> 0.000</td> <td>   27.984</td> <td>   41.237</td>
</tr>
<tr>
  <th>temperature</th> <td>    0.7654</td> <td>    0.144</td> <td>    5.334</td> <td> 0.000</td> <td>    0.471</td> <td>    1.059</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.587</td> <th>  Durbin-Watson:     </th> <td>   1.960</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.746</td> <th>  Jarque-Bera (JB):  </th> <td>   0.290</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.240</td> <th>  Prob(JB):          </th> <td>   0.865</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.951</td> <th>  Cond. No.          </th> <td>    52.5</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.



#### 해석 : 기온이 맥주 매상에 영향을 미친다는 것을 알 수 있음
- std err : 계수의 표준오차
- P>|t| : 귀무가설을 계수의 값이 0이라고 했을 때의 p값
- 95% 신뢰구간의 하측신뢰한계와 상측신뢰한계
                             
- Df Residuals : 샘플사이즈에서 추정된 파라미터 수를 뺀 것
- Df Models : 사용된 독립변수의 수
- Covariance Type : 공분산 타입. 특별히 지정하지 않으면 nonrobust가 됨
- R-squared, Adj. R-squared : 결정계수와 자유도 조정이 끝난 결정계수
 - 결정계수는 가지고 있는 데이터에 대해 모델을 적용했을 때의 적합도를 평가한 지표
 - 모델에 의한 추측치가 종속변수의 실젯값과 일치하면 R-squared는 1이 됨
 - 종속변숫값의 변동 크기를 모델로 설명 가능한 변동과 모델로 설명하지 못하는 잔차제곱합을 분해할 수 있는데 결정계수는 전체 변동폭의 크기에 대한 모델로 설명 가능한 변동폭의 비율이라고 할 수 있음
- F-statistic, Prob(F-statistic) : 분산분석 결과
 - 분산분석은 평균값의 차이를 검정하는 방법
 - 분산분석을 사용할 때는 세 개 이상의 수준 간의 평균값에 차이가 있는 지 검정할 경우임
 - 모집단이 정규분포를 따르는 데이터에 대해서만 적용. 수준 사이의 분산값이 다르지 않다는 조건도 충족해야 함
 - F비 = 효과의 분산 크기 / 오차의 분산 크기. F비가 크면 오차에 비해 효과의 영향이 클 것이라고 판단
 - 분산의 비율을 취한 통계량으로 검정을 시행하기 때문에 분산분석 또는 ANOVA라고 부름
 - F분표의 누적분포함수를 사용해서 p값을 계산하고 p값이 0.05 이하가 되면 귀무가설을 기각함
- Log-Likelihood : 최대로그우도
- AIC : 아카이케 정보 기준
- BIC : 베이즈 정보 기준


```python
# Null 모델 AIC

null_model = smf.ols('beer ~ 1',data=beer).fit()
null_model.aic
```




    227.94194972563105




```python
# 독립변수가 있는 모델의 AIC
# 독립변수가 있는 모델의 AIC가 더 작으므로 예측 정확도가 높음
lm_model = smf.ols(formula = 'beer ~ temperature', data=beer).fit()
lm_model.aic
```




    208.9090293557544




```python
# 사용된 독립변수의 수
lm_model.df_model
```




    1.0




```python
# 추정된 모델에 predict() 함수 적용
lm_model.predict()
```




    array([50.3014808 , 53.74590495, 42.26449113, 55.20021737, 46.70397114,
           37.82501112, 44.94348769, 54.51133254, 52.44467805, 41.11634975,
           54.66441806, 49.22988218, 53.21010564, 52.44467805, 41.03980699,
           52.59776357, 45.24965873, 61.78289462, 55.42984564, 50.3014808 ,
           42.41757665, 50.3014808 , 51.14345115, 40.6570932 , 66.91125946,
           52.9039346 , 62.85449324, 41.42252079, 62.47177945, 39.50895182])




```python
lm_model.params
```




    Intercept      34.610215
    temperature     0.765428
    dtype: float64




```python
# 기온이 20도일 때의 맥주 매상의 기대값
lm_model.predict(pd.DataFrame({"temperature":[20]}))
```




    0    49.918767
    dtype: float64




```python
# 잔차 계산
resid = lm_model.resid
resid.head()
```




    0    -5.001481
    1     5.554095
    2    -1.864491
    3   -17.200217
    4    -9.703971
    dtype: float64




```python
# beta0 + beta1 * 20
beta0 = lm_model.params[0]
beta1 = lm_model.params[1]
temperature = 20
beta0 + beta1 * temperature
```




    49.91876701095053




```python
y_hat = beta0 + beta1 * beer.temperature
y_hat.head(3)
```




    0    50.301481
    1    53.745905
    2    42.264491
    Name: temperature, dtype: float64




```python
lm_model.predict()[:3]
```




    array([50.3014808 , 53.74590495, 42.26449113])




```python
# 잔차(실제값 - 예측값)
(beer.beer - y_hat).head(3)
```




    0   -5.001481
    1    5.554095
    2   -1.864491
    dtype: float64




```python
# 결정계수
# R-squared는 가지고 있는 데이터에 대해 모델을 적용했을 때의 적합도를 평가한 지표
# 모델에 의한 추측치가 종속변수의 실제값과 일치하면 1이 됨

mu = np.mean(beer.beer)
y = beer.beer
yhat = lm_model.predict()

np.sum((yhat-mu)**2 / np.sum((y-mu)**2))
```




    0.5039593230611878




```python
lm_model.rsquared
```




    0.5039593230611856




```python
# 전체 변동폭의 크기에 대한 모델로 설명 가능한 변동폭의 비율
1-np.sum(resid**2) / np.sum((y-mu)**2)
```




    0.5039593230611856




```python
# 수정된 결정계수 :  독립변수가 늘어가는 것에 대해 패널티를 적용한 결정계수
# s : 독립변수의 개수
n = len(beer.beer)
s = 1
1-((np.sum(resid**2) / (n-s-1)) / (np.sum((y-mu)**2)/(n-1)))
```




    0.4862435845990851




```python
# 잔차 그래프
import warnings
warnings.filterwarnings('ignore')
sns.distplot(resid, color='black')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x24649442d90>




    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_21_1.png)
    



```python
# 잔차의 산점도
# x축이 적합도, y축이 잔차
# 산포가 완전 랜덤이며 상관이 없다는 것을 확인
sns.jointplot(lm_model.fittedvalues, resid,
             joint_kws={'color':'blue'},
             marginal_kws={'color':'black'})
```




    <seaborn.axisgrid.JointGrid at 0x2464a8f5070>




    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_22_1.png)
    



```python
# Q-Q플롯 : 이론상의 분위점과 실제 데이터의 분위점을 산포도 그래프로 그린 것
# 이론상의 분위점과 실제 데이터의 분위점을 구해서 그 둘을 비교하는 것으로 잔차가
# 정규분포인지를 시각적으로 판단
fig = sm.qqplot(resid, line='s')
```


    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_23_0.png)
    



```python
# 추정 결과의 표시
lm_model.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>beer</td>       <th>  R-squared:         </th> <td>   0.504</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.486</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.45</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 21 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>1.11e-05</td>
</tr>
<tr>
  <th>Time:</th>                 <td>14:25:59</td>     <th>  Log-Likelihood:    </th> <td> -102.45</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   208.9</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   211.7</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>   <td>   34.6102</td> <td>    3.235</td> <td>   10.699</td> <td> 0.000</td> <td>   27.984</td> <td>   41.237</td>
</tr>
<tr>
  <th>temperature</th> <td>    0.7654</td> <td>    0.144</td> <td>    5.334</td> <td> 0.000</td> <td>    0.471</td> <td>    1.059</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.587</td> <th>  Durbin-Watson:     </th> <td>   1.960</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.746</td> <th>  Jarque-Bera (JB):  </th> <td>   0.290</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.240</td> <th>  Prob(JB):          </th> <td>   0.865</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.951</td> <th>  Cond. No.          </th> <td>    52.5</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.




```python
# Prop(Omnibus), Prob(JB)는 잔차의 정규성에 대한 검정결과
# 귀무가설 : 잔차가 정규분포를 따른다, 대립가설 : 잔차가 정규분포라고 주장할 수 없다.
# P값이 0.05 보다 크다고 해도 검정의 비대칭성이 있으면 정규분포라고 주장할 수 없다.
# 왜도가 0보다 크면 오른쪽 자락이 길어짐. 정규분포 왜도는 0
# 첨도 : 히스토그램의 뾰족함을 측정하는 지표. 정규분포 첨도는 3
# Durbin-Watson : 잔차의 자기상관을 체크하는 지표. 2 전후라면 문제 없다고 판단
# DW 통계량이 2보다 크거나 차이가 난다면 일반화 제곱법 등의 사용 검토 필요
```

### 분산분석
- 정규선형모델 중에서 독립변수가 카테고리형 변수인 모델을 분산분석 모델이라고 하며 분산분석은 또한 검정방법의 이름이기도 함
- 분산분석은 정규선형모델에서 폭넓게 이용되는 검정방법으로 평균값의 차이를 검정하는 방법
- 평균값의 차이 겁정은 t검정을 이용하지만 세 개 이상의 수준간의 평균값 차이 검정은 분산분석을 사용
- 모집단이 정규분포을 따르는 데이터에 대해서만 적용, 또한 수준 사이의 분산값이 다르지 않다는 조건도 충족
- 자료를 분석하는 데 자료의 분산을 활용하는 통계기법으로 실험이나 관측에서 독립변수와 종속변수의 관계를 분석하는데 활용
- "온도는 생산성에 영향을 주는가?", "유통되는 약들이 당뇨에 미치는 효과는 같은가?"와 같은 과제를 분석
- 여러 정신과 환자들이 상담, 명상, 그리고 바이오 피드백 세 가지 치료법을 시도하려고 한다. 이 중에서 다른 치료법보다 나은 치료 방법이 있는가?
- 한 제조업체는 전구를 만드는 두 가지 공법이 있다. 한 방법이 다른 방법 보다 나은가?
- 서로 다른 두 학교의 학생들이 같은 시험을 치르려고 한다. 이 때 한 학교가 다른 학교보다 성적이 더 나은가?
- 독립변수는 정성적이거나 정량적일 수 있으며 예에서 온도는 정량적이며 약은 정성적임
- 온도가 인자라고 하면 10도, 20도, 30도 와 같이 몇 개의 값을 가지며 인자를 구성하는 몇 가지 특성을 수준이라 함
- 각 수준은 독립적인 모집단을 구성하고 이에 따라 확률변수가 정의됨
- 분산분석은 서로 다른 수준을 갖는 모집단들을 대상으로 그들의 평균에 의미가 있는 차이가 있는지 없는지를 검정
- 인자가 하나인 분산분석을 일원분산분석, 둘이면 이원분산분석, 셋 이상이면 통틀어 다원분산분석이라고 함
- 집단 또는 수준은 동일한 독립변수 내의 묶음을 의미한다. “씨리얼의 종류” 라는 독립변수가 있다면, 코코볼, 콘푸로스트, 오레오 오즈는 그 아래의 세 수준이 될 수 있다. “칼로리” 라는 독립변수의 경우에는 가당과 무가당 두 가지 수준을 가질 수 있음
- 일원분산분석에서는 하나의 인자의 수준만 처리가 되나 이원분산분석에서는 두 인자의 수준들이 조합되어 처리됨
- 다음의 가정에 기초
 - 모든 모집단의 확률변수는 정규분포를 갖는다
 - 모든 모집단의 확률변수의 분산은 sigma squared로 동일하다
 - 표본은 무작위로 추출되면 모든 표본은 서로 독립적이다


```python
import numpy as np
import pandas as pd
import scipy as sp
from scipy import stats

from matplotlib import pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf
import statsmodels.api as sm
sns.set()
```

#### 검정의 다중성
- 검정을 반복함으로써 유의미한 결과를 얻기 쉬어지는 문제를 검정의 다중성이라 함
- 검정을 반복하면 귀무가설이 기각되기 쉬어지고 1종 오류를 저지를 확률이 높아집니다.
- 맑음, 비, 흐림의 세가지 수준으로 매상이 달라지는지 검정할 때 맑음 대비 비, 비 대비 흐림, 맑음 대비 흐림의 3가지 조합으로 t검정을 실시하면 검정의 다중성 문제가 발생
- 반면 분산분석을 수행하면 맑음이나 비와 같은 개별 카테고리를 보는 것이 아니라 날씨에 따라 매상이 다른지 여부를 한번의 검정으로 판단

#### 분산분석의 직감적 사고방식 : F비
- 귀무가설 : 수준 간의 평균값에 차이가 없다, 대립가설 : 수준간의 평균값에 차이가 있다
- 수준이란 날씨, 물고기 종류 등과 같은 카테고리 변수를 의미
- 분산분석에서는 데이터의 변동을 오차와 효과로 분리하여 F비 계산. F비 = 효과의 분산 크기 / 오차의 분산 크기
- 효과의 크기를 군간 변동, 오차의 크기를 군내변동이라 하고 데이터의 분산을 2개의 변동으로 나눈 뒤 그 비율을 취한 것을 통계량으로 사용하여 검정 시행
- 분산의 비율을 취한 통계량으로 검정을 시행하므로 분산분석(ANOVA)이라고 부름
- F비가 크면 오차에 비해 효과의 영향이 클 것이라고 판단
- F분포의 누적분포함수를 사용해서 p값을 계산하고 p값이 0.05 이하가 되면 귀무가설을 기각


```python
# 샘플 데이터
weather = [
    "cloudy","cloudy",
    "rainy", "rainy",
    "sunny","sunny"
]
beer = [6,8,2,4,10,12]
weather_beer = pd.DataFrame({
    "beer":beer,
    "weather":weather
})
weather_beer
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>beer</th>
      <th>weather</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>cloudy</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8</td>
      <td>cloudy</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>rainy</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>rainy</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10</td>
      <td>sunny</td>
    </tr>
    <tr>
      <th>5</th>
      <td>12</td>
      <td>sunny</td>
    </tr>
  </tbody>
</table>
</div>




```python
# box plot
sns.boxplot(x="weather", y="beer",
           data = weather_beer, color="gray")
```




    <matplotlib.axes._subplots.AxesSubplot at 0x25939af7f40>




    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_31_1.png)
    



```python
# 날씨별 매상의 평균치
weather_beer.groupby("weather").mean()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>beer</th>
    </tr>
    <tr>
      <th>weather</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cloudy</th>
      <td>7</td>
    </tr>
    <tr>
      <th>rainy</th>
      <td>3</td>
    </tr>
    <tr>
      <th>sunny</th>
      <td>11</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 날씨에 의한 영향 : 2일씩 6일에 대한 날씨별 매상의 평균치
effect = [7,7,3,3,11,11]
```


```python
# effect의 흩어진 정도를 구함으로써 군간변동을 구할 수 있음
# 군간 제곱합 : 군간 변동의 분자
mu_effect = np.mean(effect)
squares_model = np.sum((effect - mu_effect)**2)
squares_model
```




    64.0




```python
# 오차는 원래 데이터에서 효과를 빼는 것으로 계산
resid = weather_beer.beer - effect
resid
```




    0   -1
    1    1
    2   -1
    3    1
    4   -1
    5    1
    Name: beer, dtype: int64




```python
# 군내 제곱합 : 오차의 평균값은 0
squares_resid = np.sum(resid**2)
squares_resid
```




    6




```python
df_model = 2 # 군간 변동의 자유도(수준의 종류 수에따라 좌우. 수준(3) - 1)
df_resid = 3 # 군내 변동의 자유도(샘플사이즈와 수준의 종류에 따라 좌우)
# 샘플(6) - 수준(3) = 3
```


```python
# 군간 평균제곱(분산)
variance_model = squares_model / df_model
variance_model
```




    32.0




```python
# 군내 평균제곱(분산)
variance_resid = squares_resid/df_resid
variance_resid
```




    2.0




```python
# F비 : 군간 분산과 군내 분산의 비
f_ratio = variance_model / variance_resid
f_ratio
```




    16.0




```python
# p값
1-sp.stats.f.cdf(x=f_ratio,dfn=df_model,dfd=df_resid)
```




    0.02509457330439091




```python
# 독립변수가 카테고리형인 일반선형모델
# 독립변수가 연속적 변수든 카테고리형 변수든 smf.ols를 사용해서 모델링 가능
# statsmodels를 이용한 분산분석(독립변수가 카테고리형)
anova_model = smf.ols("beer ~ weather",
                     data = weather_beer).fit()
```


```python
# 분산분석표
# 군간, 군내 편차제곱합, 자유도, F비, p값
sm.stats.anova_lm(anova_model, typ=2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>64.0</td>
      <td>2.0</td>
      <td>16.0</td>
      <td>0.025095</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>6.0</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 추정된 모델의 계수
anova_model.params
```




    Intercept           7.0
    weather[T.rainy]   -4.0
    weather[T.sunny]    4.0
    dtype: float64




```python
# 훈련데이터에 적용한 결과
# 독립변수를 카테고리형 변수로 한 일반선형모델의 추측치는 각 수준의 평균값과 일치
fitted = anova_model.fittedvalues
fitted
```




    0     7.0
    1     7.0
    2     3.0
    3     3.0
    4    11.0
    5    11.0
    dtype: float64




```python
# 잔차
anova_model.resid
```




    0   -1.0
    1    1.0
    2   -1.0
    3    1.0
    4   -1.0
    5    1.0
    dtype: float64




```python
beer = pd.read_csv("./dataset/7_1_beer.csv")
lm_model = smf.ols(formula = "beer ~ temperature",
                  data = beer).fit()
```


```python
df_lm_model = 1 # 추정된 파라미터(2) - 1
df_lm_resid = 28 # 샘플사이즈(30) - 추정된 파라미터 수(2)
```


```python
# 분산분석표
sm.stats.anova_lm(lm_model,typ=2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>temperature</th>
      <td>1651.532489</td>
      <td>1.0</td>
      <td>28.446984</td>
      <td>0.000011</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>1625.582178</td>
      <td>28.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 독립변수가 여럿인 모델 : 복수의 독립변수를 가지고 있어도 일반 선형모델 구조를
# 이용해서 분석, 해석, 예측
sales = pd.read_csv("./dataset/7_3_lmm.csv")
sales.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>humidity</th>
      <th>price</th>
      <th>sales</th>
      <th>temperature</th>
      <th>weather</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>29.5</td>
      <td>290</td>
      <td>229.7</td>
      <td>17.8</td>
      <td>rainy</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38.1</td>
      <td>290</td>
      <td>206.1</td>
      <td>26.1</td>
      <td>rainy</td>
    </tr>
    <tr>
      <th>2</th>
      <td>31.5</td>
      <td>290</td>
      <td>202.5</td>
      <td>22.0</td>
      <td>rainy</td>
    </tr>
  </tbody>
</table>
</div>




```python
# pairplot()
sns.pairplot(data=sales, hue='weather',palette='Blues')
```




    <seaborn.axisgrid.PairGrid at 0x25939e4af10>




    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_51_1.png)
    



```python
# 독립변수에 가격만 사용
lm_dame = smf.ols("sales ~ price", sales).fit()
lm_dame.params
```




    Intercept    113.645406
    price          0.332812
    dtype: float64




```python
sm.stats.anova_lm(lm_dame, typ=2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>price</th>
      <td>1398.392322</td>
      <td>1.0</td>
      <td>4.970685</td>
      <td>0.028064</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>27570.133578</td>
      <td>98.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 매상을 가격으로만 분석하여 문제 소지 발생
sns.lmplot(x='price',y='sales',data=sales,
          scatter_kws={'color':'blue'},
          line_kws={'color':'blue'})
```




    <seaborn.axisgrid.FacetGrid at 0x2593d0def40>




    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_54_1.png)
    



```python
# 독립변수간의 관계 조사
# 날씨별 평균값
sales.groupby('weather').mean()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>humidity</th>
      <th>price</th>
      <th>sales</th>
      <th>temperature</th>
    </tr>
    <tr>
      <th>weather</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>rainy</th>
      <td>32.126</td>
      <td>295.5</td>
      <td>205.924</td>
      <td>20.422</td>
    </tr>
    <tr>
      <th>sunny</th>
      <td>30.852</td>
      <td>309.5</td>
      <td>222.718</td>
      <td>21.102</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 날씨가 같았을 때 상품가격이 매상에 미치는 영향
# 날씨별로 보면 가격이 높아지면 매상이 줄어든다는 것을 알 수 있음
sns.lmplot(x='price',y='sales',data=sales,
          hue='weather',palette='gray')
```




    <seaborn.axisgrid.FacetGrid at 0x2593d0f9c10>




    
![png](%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_files/%EC%A0%95%EA%B7%9C%EC%84%A0%ED%98%95%EB%AA%A8%EB%8D%B8_guide_56_1.png)
    



```python
# 독립변수가 4개인 모델 추정
lm_sales = smf.ols(
"sales ~ weather + humidity + temperature + price",
data=sales).fit()
lm_sales.params
```




    Intercept           278.627722
    weather[T.sunny]     19.989119
    humidity             -0.254055
    temperature           1.603115
    price                -0.329207
    dtype: float64




```python
# typ=1은 TYPE I ANOVA, typ=2는 TYPE II ANOVA
# 일반적인 분산분석(typ=1)
# 모든 독립변수가 유의미한 것으로 되어있음 : 잘못된 검정 결과
sm.stats.anova_lm(lm_sales, typ=1).round(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>1.0</td>
      <td>7050.961</td>
      <td>7050.961</td>
      <td>38.848</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>humidity</th>
      <td>1.0</td>
      <td>1779.601</td>
      <td>1779.601</td>
      <td>9.805</td>
      <td>0.002</td>
    </tr>
    <tr>
      <th>temperature</th>
      <td>1.0</td>
      <td>2076.845</td>
      <td>2076.845</td>
      <td>11.443</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>price</th>
      <td>1.0</td>
      <td>818.402</td>
      <td>818.402</td>
      <td>4.509</td>
      <td>0.036</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>95.0</td>
      <td>17242.717</td>
      <td>181.502</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 독립변수의 순서를 바꾸어 추정
# 검정 결과가 바뀜. 습도의 p값
lm_sales_2 = smf.ols(
"sales ~ weather + temperature  + humidity+ price",
data=sales).fit()
sm.stats.anova_lm(lm_sales_2, typ=1).round(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>1.0</td>
      <td>7050.961</td>
      <td>7050.961</td>
      <td>38.848</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>temperature</th>
      <td>1.0</td>
      <td>3814.779</td>
      <td>3814.779</td>
      <td>21.018</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>humidity</th>
      <td>1.0</td>
      <td>41.667</td>
      <td>41.667</td>
      <td>0.230</td>
      <td>0.633</td>
    </tr>
    <tr>
      <th>price</th>
      <td>1.0</td>
      <td>818.402</td>
      <td>818.402</td>
      <td>4.509</td>
      <td>0.036</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>95.0</td>
      <td>17242.717</td>
      <td>181.502</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 분산분석 대신 회귀계수의 t검정 수행하면 같은 문제는 발생되지 않음.
# 검정 다중성의 문제 발생
# 검정 결과
lm_sales.summary().tables[1]
```




<table class="simpletable">
<tr>
          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>        <td>  278.6277</td> <td>   46.335</td> <td>    6.013</td> <td> 0.000</td> <td>  186.641</td> <td>  370.615</td>
</tr>
<tr>
  <th>weather[T.sunny]</th> <td>   19.9891</td> <td>    3.522</td> <td>    5.675</td> <td> 0.000</td> <td>   12.997</td> <td>   26.982</td>
</tr>
<tr>
  <th>humidity</th>         <td>   -0.2541</td> <td>    0.456</td> <td>   -0.558</td> <td> 0.578</td> <td>   -1.159</td> <td>    0.651</td>
</tr>
<tr>
  <th>temperature</th>      <td>    1.6031</td> <td>    0.443</td> <td>    3.620</td> <td> 0.000</td> <td>    0.724</td> <td>    2.482</td>
</tr>
<tr>
  <th>price</th>            <td>   -0.3292</td> <td>    0.155</td> <td>   -2.123</td> <td> 0.036</td> <td>   -0.637</td> <td>   -0.021</td>
</tr>
</table>




```python
# 순서를 바꾼 모델의 검정 결과 
# 회귀계수의 t검정에서는 독립변수의 순서가 초래하는 문제는 발생하지 안음
# 만약 흐림이라는 날씨도 있었다면 날씨의 영향을 t검정으로 판단하는 것은 검정 다중성의 문제 발생
lm_sales_2.summary().tables[1]
```




<table class="simpletable">
<tr>
          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>        <td>  278.6277</td> <td>   46.335</td> <td>    6.013</td> <td> 0.000</td> <td>  186.641</td> <td>  370.615</td>
</tr>
<tr>
  <th>weather[T.sunny]</th> <td>   19.9891</td> <td>    3.522</td> <td>    5.675</td> <td> 0.000</td> <td>   12.997</td> <td>   26.982</td>
</tr>
<tr>
  <th>temperature</th>      <td>    1.6031</td> <td>    0.443</td> <td>    3.620</td> <td> 0.000</td> <td>    0.724</td> <td>    2.482</td>
</tr>
<tr>
  <th>humidity</th>         <td>   -0.2541</td> <td>    0.456</td> <td>   -0.558</td> <td> 0.578</td> <td>   -1.159</td> <td>    0.651</td>
</tr>
<tr>
  <th>price</th>            <td>   -0.3292</td> <td>    0.155</td> <td>   -2.123</td> <td> 0.036</td> <td>   -0.637</td> <td>   -0.021</td>
</tr>
</table>




```python
# Type II ANOVA : 독립변수를 넣는 순서를 바꾸어도 검정 결과가 바뀌지 않는 분산분석
```


```python
# 모델 선택과 분산분석 : Type I ANOVA
# "sales ~ 1 + weather + humidity + temperature + price" 순서로 변수를 
# 포함시키는 모델
# Null 모델의 잔차제곱합
mod_null = smf.ols("sales ~ 1", sales).fit()
resid_sq_null = np.sum(mod_null.resid ** 2)
resid_sq_null
```




    28968.525899999993




```python
# 날씨 모델의 잔차제곱합
mod_1 = smf.ols("sales ~ weather", sales).fit()
resid_sq_1 = np.sum(mod_1.resid ** 2)
resid_sq_1
```




    21917.56499999999




```python
# 잔차제곱합의 차이
resid_sq_null - resid_sq_1
```




    7050.960900000002




```python
# 분산분석표
# 날씨의 변화에 따른 군간 편차제곱합은 모델에 날씨라는 독립변수를 추가하는 것으로 인해
# 감소하는 잔차제곱합과 일치 
sm.stats.anova_lm(mod_1).round(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>1.0</td>
      <td>7050.961</td>
      <td>7050.961</td>
      <td>31.527</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>98.0</td>
      <td>21917.565</td>
      <td>223.649</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 독립변수 humidity를 추가해서 잔차제곱합을 산출
mod_2 = smf.ols(
    "sales ~ weather + humidity", sales).fit()
resid_sq_2 = np.sum(mod_2.resid ** 2)
resid_sq_2
```




    20137.96389785176




```python
# 날씨만 있는 모델의 잔차제곱합에서 날씨 + 습도가 들어간 모델의 잔차제곱합을 뺌 
resid_sq_1 - resid_sq_2
```




    1779.60110214823




```python
# 분산분석표
sm.stats.anova_lm(mod_2).round(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>1.0</td>
      <td>7050.961</td>
      <td>7050.961</td>
      <td>33.963</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>humidity</th>
      <td>1.0</td>
      <td>1779.601</td>
      <td>1779.601</td>
      <td>8.572</td>
      <td>0.004</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>97.0</td>
      <td>20137.964</td>
      <td>207.608</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 날씨+기온을 독립변수로 가지는 모델의 잔차제곱합
mod_2_2 = smf.ols(
    "sales ~ weather + temperature", sales).fit()
resid_sq_2_2 = np.sum(mod_2_2.resid ** 2)
resid_sq_2_2
```




    18102.786426712213




```python
# 날씨 + 기온 + 습도 모델의 잔차제곱합
mod_3_2 = smf.ols(
    "sales ~ weather + temperature + humidity",sales).fit()
resid_sq_3_2 = np.sum(mod_3_2.resid ** 2)
resid_sq_3_2
```




    18061.11936158843




```python
# 날씨 + 기온 모델에 습도를 추가함으로써 감소한 잔차제곱합은
# 날씨만 있는 모델의 잔차제곱합에서 날씨 + 습도가 들어간 모델의 
# 잔차제곱합의 감소량 대비 작다는 점 주목
resid_sq_2_2 - resid_sq_3_2
```




    41.667065123783686




```python
# 분산분석표에서 humidity는 유의미하지 않음
sm.stats.anova_lm(mod_3_2).round(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df</th>
      <th>sum_sq</th>
      <th>mean_sq</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>1.0</td>
      <td>7050.961</td>
      <td>7050.961</td>
      <td>37.478</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>temperature</th>
      <td>1.0</td>
      <td>3814.779</td>
      <td>3814.779</td>
      <td>20.277</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>humidity</th>
      <td>1.0</td>
      <td>41.667</td>
      <td>41.667</td>
      <td>0.221</td>
      <td>0.639</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>96.0</td>
      <td>18061.119</td>
      <td>188.137</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



### 정리 
#### Type I ANOVA 검정방법
- 복수의 독립변수를 가지는 경우 분산분석은 독립변수를 1개씩 늘려나가서 독립변수가 늘어남으로써 감소한 잔차제곱합의 크기를 기반으로 독립변수 효과의 크기(분산분석표에서 sum_sq)를 계산
- 이 방법은 독립변수를 추가하는 순서에 따라서 sum_sq 값의 크기가 크게 바뀌며 유의미한지 여부도 변할 수 있음
- 독립변수가 여러 개 있을 경우 이 방법을 사용하면 잘못된 결과를 얻을 가능성 있음 

#### Type II ANOVA 검정방법
- 독립변수가 줄어들면서 증가하는 잔차제곱합의 크기에 기반해서 독립변수가 갖는 효과의 크기를 정량화 함
- 변수를 추가하는 순서를 바꾸어도 검정 결과는 달라지지 않음
- 계산된 군간 편차제곱합을 수정제곱합이라고 부름


```python
# Tpye II ANOVA
# 모든 변수가 포함된 모델의 잔차제곱합
mod_full = smf.ols(
    "sales ~ weather + humidity + temperature + price", sales).fit()
resid_sq_full = np.sum(mod_full.resid ** 2)
resid_sq_full
```




    17242.71694236649




```python
# 습도만 제거한 모델의 잔차제곱합
mod_non_humi = smf.ols(
    "sales ~ weather + temperature + price", sales).fit()
resid_sq_non_humi = np.sum(mod_non_humi.resid ** 2)
resid_sq_non_humi
```




    17299.142016107657




```python
resid_sq_non_humi - resid_sq_full
```




    56.42507374116758




```python
# Type II ANOVA : 수정제곱합을 이용한 분산분석으로 typ = 2라는 파라미터를 넘김으로써 
# 실행
# 습도의 p값은 0.578이고 매상에 대해 유의미한 영향을 끼치고 있다고 볼 수 없다는 판단
# 독립변수가 1개 밖에 없을 경우 Type I 과 Type II의 결과는 일치
sm.stats.anova_lm(mod_full, typ=2).round(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>5845.878</td>
      <td>1.0</td>
      <td>32.208</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>humidity</th>
      <td>56.425</td>
      <td>1.0</td>
      <td>0.311</td>
      <td>0.578</td>
    </tr>
    <tr>
      <th>temperature</th>
      <td>2378.017</td>
      <td>1.0</td>
      <td>13.102</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>price</th>
      <td>818.402</td>
      <td>1.0</td>
      <td>4.509</td>
      <td>0.036</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>17242.717</td>
      <td>95.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 2개의 모델을 직접 비교
# F비, p값, 2개 모델의 자유도
mod_full.compare_f_test(mod_non_humi)
```




    (0.3108780375696161, 0.5784533427120795, 1.0)



#### Type II ANOVA 해석
- 습도의 영향을 검정한 결과는 다른 독립변수가 있는 조건에서도 습도가 매상에 영향을 끼치고 있는지 판단할 수 있는가를 조사한 것이라고 해석할 수 있음
- 습도는 기온과 강한 상관관계가 있으며 기온이라는 독립변수가 포함되어 있으면 습도는 매상에 영향을 끼친다고 볼 수 없음
- 습도는 모델에 필요없다는 것을 알 수 있었으므로 습도를 뺀 모델 mod_non_humi에서 다시 Type II ANOVA 수행


```python
# 습도를 뺀 모델에서 Type II ANOVA 수행결과 유의미하지 않은 변수는 없음
sm.stats.anova_lm(mod_non_humi,typ=2).round(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>weather</th>
      <td>6354.966</td>
      <td>1.0</td>
      <td>35.266</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>temperature</th>
      <td>4254.736</td>
      <td>1.0</td>
      <td>23.611</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>price</th>
      <td>803.644</td>
      <td>1.0</td>
      <td>4.460</td>
      <td>0.037</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>17299.142</td>
      <td>96.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 모델의 계수 등의 결과에 대한 해석은 변수 선택 후의 모델을 이용해서 수행
# 잘못된 변수의 조합으로 모델링된 결과를 예측이나 해셕에 사용하면 잘못된 결론을 이끌어 낼 수 있음
# weather[T.sunny]는 비오는 날과 비교하면 매상이 20 증가
mod_non_humi.params
```




    Intercept           273.301800
    weather[T.sunny]     20.393871
    temperature           1.417860
    price                -0.326001
    dtype: float64




```python
# AIC를 이용한 변수 선택 : 습도를 제외한 모델의 AIC기 다 작아짐을 확인, 습도는 모델에서 제외 필요
print("모든 변수를 포함한 모델：", mod_full.aic.round(3))
print("습도를 제외한 모델　：", mod_non_humi.aic.round(3))
```

    모든 변수를 포함한 모델： 808.785
    습도를 제외한 모델　： 807.112
    


```python
# 독립변수간에 강한 상관관계가 있을 때 나타나는 문제가 다중공선성.
# 기온과 습도간의 상관관게가 강한 변수 중 어느 한쪽을 제거
# 다중공선성이 있으면 추정된 계수의 해석이 어려워지고 검정에서 얻은 p값 역시 
# 해석이 어려움
# 리지, 라쏘회귀 등을 이용함으로써 이런 문제를 완화할 수 있음
```
