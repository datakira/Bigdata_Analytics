```python
import numpy as np
import pandas as pd

from sklearn.neural_network import MLPClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

```



```python
iris = load_iris()
iris.feature_names
```




    ['sepal length (cm)',
     'sepal width (cm)',
     'petal length (cm)',
     'petal width (cm)']




```python
X = iris.data[50:150, 0:2]
y = iris.target[50:150]
print("독립변수의 행, 열 수 :", X.shape)
print("종속변수의 행, 열 수 :", y.shape)
```

    독립변수의 행, 열 수 : (100, 2)
    종속변수의 행, 열 수 : (100,)
    


```python
# 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(
X, y, random_state=2)
print(X_train.shape)
X_test.shape
```

    (75, 2)
    




    (25, 2)




```python
# 신경망
scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```


```python
# 은닉층에 100개의 유닛을 배치, 입출력까지 합쳐서 모두 4개의 신경망
# alpha는 정규화 강도를 지정
# max_iter는 파라미터 추정을 위해 최대 몇 번이나 반복 계산을 할 지 지정
# 활성화 함수는 ReLU가 쓰였고 파라미터 추정 알고리즘으로는 Adam이 디폴트로 지정

nnet = MLPClassifier(
    hidden_layer_sizes=(100,100),
    alpha = 0.07,
    max_iter = 10000,
    random_state = 0)
nnet.fit(X_train_scaled, y_train)

print("훈련데이터 적중률:", nnet.score(X_train_scaled,y_train))
print("테스트데이터 적중률:", nnet.score(X_test_scaled,y_test))
```

    훈련데이터 적중률: 0.8933333333333333
    테스트데이터 적중률: 0.68
    
